{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6596179",
   "metadata": {},
   "source": [
    "# Logic gates using neural networks via Keras (Tensorflow)\n",
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "Here we are using Keras which is supposedly a high level API for Tensorflow, or that it uses Tensorflow as backend.\n",
    "\n",
    "However, it has been recently advocated that one should use 'tf.keras' instead. This is essentially, keras being included as a submodule inside tensorflow itself.\n",
    "\n",
    "https://www.pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8ee9311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b3784",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9c302352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([[0.,0.,1.,1.],[0.,1.,0.,1.]]).T\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0823c",
   "metadata": {},
   "source": [
    "## Expected outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b282e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND function\n",
    "outputAND = np.array([0.,0.,0.,1.])\n",
    "outputAND = np.asarray([outputAND]).T\n",
    "# OR function\n",
    "outputOR = np.array([0.,1.,1.,1.])\n",
    "outputOR = np.asarray([outputOR]).T\n",
    "# NAND function\n",
    "outputNAND = np.array([1.,1.,1.,0.])\n",
    "outputNAND = np.asarray([outputNAND]).T\n",
    "# XOR function\n",
    "outputXOR = np.array([0.,1.,1.,1.])\n",
    "outputXOR = np.asarray([outputXOR]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e226e4",
   "metadata": {},
   "source": [
    "## Set initial weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8b59d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights matrices:  [array([[0.3 , 0.45],\n",
      "       [0.55, 0.5 ],\n",
      "       [0.2 , 0.35]]), array([[0.15, 0.4 , 0.25]])]\n",
      "Biases:  [array([0.6, 0.6, 0.6]), array([0.05])]\n"
     ]
    }
   ],
   "source": [
    "# Initial guesses for weights\n",
    "w1 = 0.30\n",
    "w2 = 0.55\n",
    "w3 = 0.20\n",
    "w4 = 0.45\n",
    "w5 = 0.50\n",
    "w6 = 0.35\n",
    "w7 = 0.15\n",
    "w8 = 0.40\n",
    "w9 = 0.25\n",
    "\n",
    "# Initial guesses for biases\n",
    "b1 = 0.60\n",
    "b2 = 0.05\n",
    "\n",
    "# need to use a list instead of a numpy array, since the \n",
    "#weight matrices at each layer are not of the same dimensions\n",
    "weights = [] \n",
    "# Weights for layer 1 --> 2\n",
    "weights.append(np.array([[w1,w4],[w2, w5], [w3, w6]]))\n",
    "# Weights for layer 2 --> 3\n",
    "weights.append(np.array([[w7, w8, w9]]))\n",
    "# List of biases at each layer\n",
    "biases = []\n",
    "biases.append(np.array([b1,b1,b1]))\n",
    "biases.append(np.array([b2]))\n",
    "\n",
    "weightsOriginal = weights\n",
    "biasesOriginal = biases\n",
    "\n",
    "print('Weights matrices: ',weights)\n",
    "print('Biases: ',biases)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e563b725",
   "metadata": {},
   "source": [
    "## Some more settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6c671658",
   "metadata": {},
   "outputs": [],
   "source": [
    "nLayers = 2\n",
    "nSamples = 4\n",
    "eeta = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf75a2d",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e7bd8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=2, activation='sigmoid', use_bias=True))\n",
    "model.add(Dense(1, activation='sigmoid', use_bias=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee08c5",
   "metadata": {},
   "source": [
    "## Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "32ebc2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f70d80",
   "metadata": {},
   "source": [
    "## Check the initial weights and biases for each layer\n",
    "\n",
    "Note how the weights matrix is not 3x2 but rather 2x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "203945e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weights for layer  1\n",
      "[[-1.0776986   0.29754436  0.24226391]\n",
      " [ 0.15691936  0.22695196  0.70656633]]\n",
      "\n",
      " Biases for layer  1\n",
      "[0. 0. 0.]\n",
      "\n",
      " Weights for layer  2\n",
      "[[ 0.18757391]\n",
      " [-0.49709475]\n",
      " [ 0.16926765]]\n",
      "\n",
      " Biases for layer  2\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(nLayers):\n",
    "    print('\\n Weights for layer ',i+1)\n",
    "    print(model.layers[i].get_weights()[0])\n",
    "    print('\\n Biases for layer ',i+1)\n",
    "    print(model.layers[i].get_weights()[1])\n",
    "# model.layers[0].get_biases()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f23aefc",
   "metadata": {},
   "source": [
    "## Change initial weights and biases for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "30406592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "model.layers[0].set_weights([weightsOriginal[0].T, biasesOriginal[0]])\n",
    "\n",
    "# Layer 2\n",
    "model.layers[1].set_weights([weightsOriginal[1].T, biasesOriginal[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e8437",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "393cec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "\n",
    "# In the following manner we can't set the learning rate of the optimizer\n",
    "# model.compile(loss='mse', optimizer='sgd', metrics=['mse'])\n",
    "\n",
    "# So use the following instead\n",
    "model.compile(loss='mse', optimizer=optimizers.SGD(learning_rate=0.5), metrics=['mse'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42bd16",
   "metadata": {},
   "source": [
    "## Forward feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d7f7440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "4/1 [========================================================================================================================] - 0s 36ms/sample - loss: 0.3434 - mse: 0.3434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3434138894081116, 0.3434139]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputs, outputAND, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f9e34",
   "metadata": {},
   "source": [
    "## Does tf.model.evaluate change the weights and biases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b3c3565d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weights for layer  1\n",
      "[[0.3  0.55 0.2 ]\n",
      " [0.45 0.5  0.35]]\n",
      "\n",
      " Biases for layer  1\n",
      "[0.6 0.6 0.6]\n",
      "\n",
      " Weights for layer  2\n",
      "[[0.15]\n",
      " [0.4 ]\n",
      " [0.25]]\n",
      "\n",
      " Biases for layer  2\n",
      "[0.05]\n"
     ]
    }
   ],
   "source": [
    "for i in range(nLayers):\n",
    "    print('\\n Weights for layer ',i+1)\n",
    "    print(model.layers[i].get_weights()[0])\n",
    "    print('\\n Biases for layer ',i+1)\n",
    "    print(model.layers[i].get_weights()[1])\n",
    "# model.layers[0].get_biases()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a82c73",
   "metadata": {},
   "source": [
    "From the above, we can be sure that it does not change the weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631266fa",
   "metadata": {},
   "source": [
    "## Fit 1 epoch  (forward feed, backpropagation, updating the weights, biases)\n",
    "\n",
    "Let us just try to see and compare the error after just 1 epoch. \n",
    "\n",
    "We should expect the model to perform forward feed, calculate loss/error,\n",
    "perform backpropagation,\n",
    "and adjust the weights and biases based on the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2172efeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples\n",
      "4/4 [==============================] - 0s 93ms/sample - loss: 0.3434 - mse: 0.3434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x141218f10>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(inputs, outputAND, epochs=1, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc310a",
   "metadata": {},
   "source": [
    "## Now the weights and biases must have been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e18530de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weights for layer  1\n",
      "[[0.29931322 0.54829705 0.1988662 ]\n",
      " [0.4493876  0.49822634 0.34898397]]\n",
      "\n",
      " Biases for layer  1\n",
      "[0.5969832 0.5921526 0.5948988]\n",
      "\n",
      " Weights for layer  2\n",
      "[[0.08719039]\n",
      " [0.33587077]\n",
      " [0.1880536 ]]\n",
      "\n",
      " Biases for layer  2\n",
      "[-0.04234041]\n"
     ]
    }
   ],
   "source": [
    "for i in range(nLayers):\n",
    "    print('\\n Weights for layer ',i+1)\n",
    "    print(model.layers[i].get_weights()[0])\n",
    "    print('\\n Biases for layer ',i+1)\n",
    "    print(model.layers[i].get_weights()[1])\n",
    "# model.layers[0].get_biases()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8691ba72",
   "metadata": {},
   "source": [
    "## Now let us do a forward feed again and calculate the loss/error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "85c03ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/1 [========================================================================================================================] - 0s 738us/sample - loss: 0.3041 - mse: 0.3041\n",
      "[0.30411168932914734, 0.3041117]\n"
     ]
    }
   ],
   "source": [
    "out = model.evaluate(inputs, outputAND, batch_size=4)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5fe4a2",
   "metadata": {},
   "source": [
    "### The above result, compares well with the PyTorch result as well as the result from my own implementation (when biases are updated independently)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f873d0a",
   "metadata": {},
   "source": [
    "## Now let us let the model train for 10^4 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8281c05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 s, sys: 4.43 s, total: 32.6 s\n",
      "Wall time: 16.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1415df9d0>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the keras model on the dataset\n",
    "model.fit(inputs, outputAND, epochs=10**4, batch_size=4, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6a357",
   "metadata": {},
   "source": [
    "Turns out that this was quite slow. At first, I thought that the problem was that it was printing at each epoch. So I set the verbose=0 (silent). But still, it was incredibly slow compared to my implementation as well as PyTorch, even though we used own for loop in both the cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b6d5c",
   "metadata": {},
   "source": [
    "## Well, now let us check the output as well as the new weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bb2aaff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/1 [========================================================================================================================] - 0s 752us/sample - loss: 2.3155e-04 - mse: 2.3155e-04\n",
      "[0.00023155275266617537, 0.00023155275]\n"
     ]
    }
   ],
   "source": [
    "out = model.evaluate(inputs, outputAND, batch_size=4, verbose=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cac1f5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weights for layer  1\n",
      "[[-0.06779443  3.6265924  -1.9713068 ]\n",
      " [ 0.05656041  3.656049   -1.9379458 ]]\n",
      "\n",
      " Biases for layer  1\n",
      "[ 0.74201846 -5.253187    2.5809646 ]\n",
      "\n",
      " Weights for layer  2\n",
      "[[-0.30047134]\n",
      " [ 8.487755  ]\n",
      " [-4.2936563 ]]\n",
      "\n",
      " Biases for layer  2\n",
      "[-2.5681338]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(nLayers):\n",
    "    print('\\n Weights for layer ',i+1)\n",
    "    print(model.layers[i].get_weights()[0])\n",
    "    print('\\n Biases for layer ',i+1)\n",
    "    print(model.layers[i].get_weights()[1])\n",
    "# model.layers[0].get_biases()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f22db",
   "metadata": {},
   "source": [
    "## Now also let us have a look at the predictions for the sake of the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0f0a272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00120634]\n",
      " [0.01536182]\n",
      " [0.01545322]\n",
      " [0.97878754]]\n"
     ]
    }
   ],
   "source": [
    "# make probability predictions with the model\n",
    "predictions = model.predict(inputs)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906a6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
